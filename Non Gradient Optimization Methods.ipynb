{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark function, Rosenbrock, global minima at x = 1\n",
    "def rosen(x):\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosen_with_noise(x, mu, sigma):\n",
    "    # assume normal distributed noise\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0) + np.random.normal(mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sphere(x):\n",
    "    return sum(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rastrigin(x):\n",
    "    return sum(10+x**2-10*np.cos(2*np.pi*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(n, bounds):\n",
    "    # generates a np array of n rows of random values that lies within the range given by bounds array\n",
    "    # bounds array is a list of tuples, each tuple indicate the (min value, max_value) for given dimension\n",
    "    # length of bounds is assumed to define the number of dimensions required\n",
    "    bounds_range = np.apply_along_axis(lambda x:x[1]-x[0], 1, np.array(bounds))\n",
    "    bounds_min = np.apply_along_axis(lambda x:x[0], 1, np.array(bounds))\n",
    "    p_set_norm = np.random.rand(1, len(bounds))\n",
    "    \n",
    "    for i in range(n-1):\n",
    "        p = np.random.rand(1, len(bounds))*bounds_range+bounds_min\n",
    "        p_set_norm = np.vstack([p_set_norm, p])\n",
    "        \n",
    "    p_set = p_set_norm*bounds_range+bounds_min    \n",
    "    return p_set_norm, p_set\n",
    "\n",
    "def select_vectors(p_set, r, exclude_i):\n",
    "    # chooses r vectors from the p_set, excluding the one at index: exclude_i \n",
    "    n = len(p_set)    \n",
    "    idexes = [idx for idx in range(n) if idx != exclude_i]\n",
    "    return p_set[np.random.choice(idexes, 3, replace=False)]\n",
    "\n",
    "def get_trial_vector(vectors, c):\n",
    "    # calculate trial vector using the 3 vector provided\n",
    "    if len(vectors) != 3:\n",
    "        return\n",
    "    return vectors[0] + c*(vectors[1] - vectors[2])\n",
    "\n",
    "def crossover(parent, trial_vector, pcr):\n",
    "    # if pcr = 1, means all choose from trial vector, if 0, means all choose from parent vector\n",
    "    choose_trial = np.random.rand(1,len(trial_vector)) <= pcr\n",
    "    return (choose_trial*trial_vector + (1-choose_trial)*parent)[0]\n",
    "    \n",
    "def differential_evolution(f, bounds, c=0.8, pcr=0.7, n=15, max_iter=1000, \n",
    "                           max_eval=1000000, init='latin'):\n",
    "    # finds minimal for function f subject to boundary given by bounds.    \n",
    "    # hyperparamters:\n",
    "    # n random starting positions\n",
    "    # c is the weight to multiply for the vector differential\n",
    "    # pcr is the rate of crossover\n",
    "    \n",
    "    # initialize n random starting positions\n",
    "    d = len(bounds) # dimension of inputs\n",
    "    p_set_norm, p_set = initialize(n, bounds)\n",
    "    bounds_range = np.apply_along_axis(lambda x:x[1]-x[0], 1, np.array(bounds))\n",
    "    bounds_min = np.apply_along_axis(lambda x:x[0], 1, np.array(bounds))\n",
    "    \n",
    "    # positions variables\n",
    "    fitness = np.apply_along_axis(f, 1, p_set)\n",
    "    mean_fitness = np.mean(fitness)\n",
    "    best_fitness = np.min(fitness)\n",
    "    best_position = p_set[np.argmin(fitness)]\n",
    "    best_position_list = []\n",
    "    \n",
    "    # loop variables\n",
    "    terminate = False\n",
    "    itr = 0\n",
    "    i_no_improvement = 0\n",
    "    evals = n\n",
    "    \n",
    "    while not terminate:\n",
    "        for i in range(n):\n",
    "            # select 3 other vectors from the positions and compute trial vector\n",
    "            trial_vector = get_trial_vector(select_vectors(p_set_norm, 3, i), c)\n",
    "            \n",
    "            # crossover\n",
    "            offspring_norm = crossover(p_set_norm[i], trial_vector, pcr)\n",
    "            offspring_norm = np.clip(offspring_norm, 0, 1)\n",
    "            offspring = offspring_norm*bounds_range+bounds_min \n",
    "            \n",
    "            # select fitter between offspring and parent\n",
    "            # minimization problem\n",
    "            offspring_fitness = f(offspring)\n",
    "            evals += 1\n",
    "            if offspring_fitness < f(p_set[i]):\n",
    "                p_set[i] = offspring\n",
    "                p_set_norm[i] = offspring_norm\n",
    "                \n",
    "                if offspring_fitness < best_fitness:\n",
    "                    best_fitness = offspring_fitness\n",
    "                    p_set[np.argmin(fitness)] = offspring\n",
    "                    p_set_norm[np.argmin(fitness)] = offspring_norm\n",
    "                    fitness[np.argmin(fitness)] = offspring_fitness\n",
    "                    best_position = offspring\n",
    "    \n",
    "        best_position_list.append(best_position)\n",
    "        \n",
    "        # check for termination criteria\n",
    "        if np.mean(fitness) >= mean_fitness:\n",
    "            i_no_improvement += 1\n",
    "        else:\n",
    "            mean_fitness = np.mean(fitness)\n",
    "            i_no_improvement = 0\n",
    "        \n",
    "        if itr > max_iter:\n",
    "            terminate = True\n",
    "        elif i_no_improvement > 100:\n",
    "            terminate = True\n",
    "        \n",
    "        if evals > max_eval:\n",
    "            terminate = True\n",
    "            \n",
    "        itr +=1\n",
    "    \n",
    "    print('the best solution is {} and function value is {}'.format(best_position, best_fitness))\n",
    "    print('number of iterations: {}'.format(itr))\n",
    "    return best_position_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Space\n",
    "from skopt.sampler import Lhs\n",
    "\n",
    "def differential_evolution(f, bounds, mut=0.8, crossp=0.7, popsize=20, \n",
    "                           its=1000, init='latin', max_eval=1000000, display=False):\n",
    "    dimensions = len(bounds)\n",
    "    \n",
    "    # initialize positions\n",
    "    if init == 'random':\n",
    "        pop = np.random.rand(popsize, dimensions)\n",
    "    else:\n",
    "        space = Space([(0.,1.)]*dimensions)\n",
    "        lhs = Lhs()\n",
    "        pop = np.asarray(lhs.generate(space.dimensions, popsize))\n",
    "    \n",
    "    min_b, max_b = np.asarray(bounds).T\n",
    "    diff = max_b - min_b\n",
    "    pop_denorm = min_b + pop * diff\n",
    "    \n",
    "    # compute fitness\n",
    "    fitness = np.apply_along_axis(f, 1, pop_denorm)\n",
    "    best_idx = np.argmin(fitness)\n",
    "    best = pop_denorm[best_idx]\n",
    "    evals = popsize\n",
    "    \n",
    "    # main iteration\n",
    "    for i in range(its):\n",
    "        for j in range(popsize):\n",
    "            # generate 3 other random vectors \n",
    "            idxs = [idx for idx in range(popsize) if idx != j]\n",
    "            a, b, c = pop[np.random.choice(idxs, 3, replace = False)]\n",
    "            \n",
    "            # compute trial vector and perform boundary check\n",
    "            # perform cross over\n",
    "            mutant = np.clip(a + mut * (b - c), 0, 1)\n",
    "            cross_points = np.random.rand(dimensions) < crossp\n",
    "            trial = cross_points*mutant + (1-cross_points)*pop[j]\n",
    "            trial_denorm = min_b + trial * diff\n",
    "            \n",
    "            # compute fitness of trial vector\n",
    "            trial_fitness = f(trial_denorm)\n",
    "            evals += 1\n",
    "            \n",
    "            if trial_fitness < fitness[j]:\n",
    "                fitness[j] = trial_fitness\n",
    "                pop[j] = trial\n",
    "                if trial_fitness < fitness[best_idx]:\n",
    "                    best_idx = j\n",
    "                    best = trial_denorm\n",
    "        if display:\n",
    "            print('differential evolution step {}: f(x)= {}'.format(i, fitness[best_idx]))\n",
    "        \n",
    "        if evals > max_eval:\n",
    "            break\n",
    "    print('number of iterations: {}'.format(i))\n",
    "    return best, fitness[best_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on bechmark function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of iterations: 49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.51863147,  0.71002881,  0.44160522, -0.80983969,  0.50133622]),\n",
       " 50.06424245885889)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = [(-10,10)]*5\n",
    "differential_evolution(rosen, bounds, popsize=20, max_eval=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison to Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_DE(xk, convergence):\n",
    "    if convergence > 1:\n",
    "        print(xk)\n",
    "        return True\n",
    "    else:\n",
    "        print(xk)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= 4751.79\n",
      "[-0.79640259 -1.1030052  -2.24405189 -0.55252075 -0.73813223]\n",
      "differential_evolution step 2: f(x)= 576.439\n",
      "[ 1.32018382  1.22179992  1.62870617  0.32773174 -0.13549013]\n",
      "differential_evolution step 3: f(x)= 555.862\n",
      "[-0.80692646  1.11078903  0.14769046 -0.13389329  2.04041332]\n",
      "differential_evolution step 4: f(x)= 393.453\n",
      "[-0.48792209 -0.21073986 -0.2526003   1.12681204 -0.29945183]\n",
      "differential_evolution step 5: f(x)= 111.441\n",
      "[-0.05322571  0.52782688  1.16324545  1.15103667  1.28567587]\n",
      "differential_evolution step 6: f(x)= 90.4073\n",
      "[1.02345893 1.05222747 1.02373222 1.71734909 2.28302122]\n",
      "differential_evolution step 7: f(x)= 90.4073\n",
      "[1.02345893 1.05222747 1.02373222 1.71734909 2.28302122]\n",
      "differential_evolution step 8: f(x)= 63.422\n",
      "[0.88340862 0.77320677 1.24965142 1.13383938 1.44327775]\n",
      "differential_evolution step 9: f(x)= 3.67864\n",
      "[1.03561634 1.00482002 0.86296938 0.82771395 0.74255921]\n",
      "differential_evolution step 10: f(x)= 3.67864\n",
      "[1.03561634 1.00482002 0.86296938 0.82771395 0.74255921]\n",
      "differential_evolution step 11: f(x)= 3.67864\n",
      "[1.03561634 1.00482002 0.86296938 0.82771395 0.74255921]\n",
      "differential_evolution step 12: f(x)= 3.58531\n",
      "[0.79802203 0.69554815 0.61020004 0.46240229 0.16310847]\n",
      "differential_evolution step 13: f(x)= 3.13793\n",
      "[ 0.77582561  0.64972155  0.31674587  0.08891873 -0.04827802]\n",
      "differential_evolution step 14: f(x)= 3.13793\n",
      "[ 0.77582561  0.64972155  0.31674587  0.08891873 -0.04827802]\n",
      "differential_evolution step 15: f(x)= 3.13793\n",
      "[ 0.77582561  0.64972155  0.31674587  0.08891873 -0.04827802]\n",
      "differential_evolution step 16: f(x)= 3.13793\n",
      "[ 0.77582561  0.64972155  0.31674587  0.08891873 -0.04827802]\n",
      "differential_evolution step 17: f(x)= 2.45165\n",
      "[0.77256033 0.65905306 0.39677867 0.10671066 0.06939246]\n",
      "differential_evolution step 18: f(x)= 2.45165\n",
      "[0.77256033 0.65905306 0.39677867 0.10671066 0.06939246]\n",
      "differential_evolution step 19: f(x)= 2.45165\n",
      "[0.77256033 0.65905306 0.39677867 0.10671066 0.06939246]\n",
      "differential_evolution step 20: f(x)= 2.35502\n",
      "[ 0.71409178  0.5404106   0.3688206   0.10431926 -0.01713139]\n",
      "differential_evolution step 21: f(x)= 2.35502\n",
      "[ 0.71409178  0.5404106   0.3688206   0.10431926 -0.01713139]\n",
      "differential_evolution step 22: f(x)= 1.92899\n",
      "[0.88477186 0.77833645 0.50293252 0.26418562 0.07693246]\n",
      "differential_evolution step 23: f(x)= 1.92899\n",
      "[0.88477186 0.77833645 0.50293252 0.26418562 0.07693246]\n",
      "differential_evolution step 24: f(x)= 1.92899\n",
      "[0.88477186 0.77833645 0.50293252 0.26418562 0.07693246]\n",
      "differential_evolution step 25: f(x)= 1.64405\n",
      "[0.77715761 0.65956415 0.45012559 0.16842512 0.00941831]\n",
      "differential_evolution step 26: f(x)= 1.64405\n",
      "[0.77715761 0.65956415 0.45012559 0.16842512 0.00941831]\n",
      "differential_evolution step 27: f(x)= 1.63226\n",
      "[ 0.78560213  0.67580847  0.47009432  0.2043415  -0.00042   ]\n",
      "differential_evolution step 28: f(x)= 1.63226\n",
      "[ 0.78560213  0.67580847  0.47009432  0.2043415  -0.00042   ]\n",
      "differential_evolution step 29: f(x)= 1.48597\n",
      "[0.80380673 0.68150725 0.465717   0.28153462 0.08247798]\n",
      "differential_evolution step 30: f(x)= 1.31041\n",
      "[0.83797332 0.70570587 0.49234749 0.30399586 0.11917945]\n",
      "differential_evolution step 31: f(x)= 1.31041\n",
      "[0.83797332 0.70570587 0.49234749 0.30399586 0.11917945]\n",
      "differential_evolution step 32: f(x)= 1.08862\n",
      "[0.85188759 0.7575092  0.62069435 0.35049539 0.12498782]\n",
      "differential_evolution step 33: f(x)= 0.840735\n",
      "[0.92146418 0.87170164 0.71498669 0.4976753  0.2014486 ]\n",
      "differential_evolution step 34: f(x)= 0.840735\n",
      "[0.92146418 0.87170164 0.71498669 0.4976753  0.2014486 ]\n",
      "differential_evolution step 35: f(x)= 0.840735\n",
      "[0.92146418 0.87170164 0.71498669 0.4976753  0.2014486 ]\n",
      "differential_evolution step 36: f(x)= 0.840735\n",
      "[0.92146418 0.87170164 0.71498669 0.4976753  0.2014486 ]\n",
      "differential_evolution step 37: f(x)= 0.482375\n",
      "[0.92340184 0.84121243 0.74761668 0.57152912 0.31432449]\n",
      "differential_evolution step 38: f(x)= 0.334136\n",
      "[0.92089598 0.84895394 0.73165893 0.53147527 0.28288396]\n",
      "differential_evolution step 39: f(x)= 0.293885\n",
      "[0.93900326 0.87466993 0.75423043 0.58456596 0.34285871]\n",
      "differential_evolution step 40: f(x)= 0.293885\n",
      "[0.93900326 0.87466993 0.75423043 0.58456596 0.34285871]\n",
      "differential_evolution step 41: f(x)= 0.293885\n",
      "[0.93900326 0.87466993 0.75423043 0.58456596 0.34285871]\n",
      "differential_evolution step 42: f(x)= 0.270281\n",
      "[0.9502745  0.89742683 0.78724436 0.62054728 0.36719785]\n",
      "differential_evolution step 43: f(x)= 0.242431\n",
      "[0.94822798 0.88349691 0.78558991 0.62470851 0.39842708]\n",
      "differential_evolution step 44: f(x)= 0.242431\n",
      "[0.94822798 0.88349691 0.78558991 0.62470851 0.39842708]\n",
      "differential_evolution step 45: f(x)= 0.208918\n",
      "[0.95686618 0.91382682 0.84505967 0.71735237 0.48553892]\n",
      "differential_evolution step 46: f(x)= 0.208918\n",
      "[0.95686618 0.91382682 0.84505967 0.71735237 0.48553892]\n",
      "differential_evolution step 47: f(x)= 0.208918\n",
      "[0.95686618 0.91382682 0.84505967 0.71735237 0.48553892]\n",
      "differential_evolution step 48: f(x)= 0.208918\n",
      "[0.95686618 0.91382682 0.84505967 0.71735237 0.48553892]\n",
      "differential_evolution step 49: f(x)= 0.18909\n",
      "[0.95138433 0.89457929 0.80731984 0.65856007 0.43025727]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.95138433, 0.89457929, 0.80731984, 0.65856007, 0.43025727]),\n",
       " 0.18909022669799003)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import rosen, differential_evolution\n",
    "result = differential_evolution(rosen, bounds, popsize=20, maxiter=49, disp=True, callback=callback_DE, polish=False)\n",
    "result.x, result.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(fitness, n):\n",
    "    # calculate probability of each p being selected as a parent\n",
    "    f_inv = 1/(fitness/fitness.sum())\n",
    "    prob = f_inv/f_inv.sum()\n",
    "    # selecting n set of parents\n",
    "    indexes = np.argsort(prob)[::-1]\n",
    "    prob = np.sort(prob)[::-1]\n",
    "    parents = []\n",
    "    position = len(fitness)\n",
    "    for i in range(n):\n",
    "        parent = []\n",
    "        for i in range(2):\n",
    "            r = rand.random()\n",
    "            for j in range(position):\n",
    "                if r < prob[j]:\n",
    "                    parent.append(indexes[j])\n",
    "                    break\n",
    "                else:\n",
    "                    r -= prob[j]\n",
    "        parents.append(parent)\n",
    "    return parents\n",
    "        \n",
    "def crossover(p_set, parents):\n",
    "    # keep bits that are similar and perform uniform crossover for the rest\n",
    "    n = len(parents)\n",
    "    d = len(p_set[0])\n",
    "    new_p_set = np.copy(p_set)\n",
    "    for i in range(n):\n",
    "        parent_A = p_set[parents[i][0]]\n",
    "        parent_B = p_set[parents[i][1]]\n",
    "        \n",
    "        # go over each dimension and crossover if neccessary\n",
    "        child_i = []\n",
    "        for j in range(d):\n",
    "            A_j = parent_A[j]\n",
    "            B_j = parent_B[j]\n",
    "            \n",
    "            if abs(A_j - B_j) < 0.05:\n",
    "                child_i.append((A_j + B_j)/2)\n",
    "            elif rand.random() < 0.5:\n",
    "                child_i.append(A_j)\n",
    "            else:\n",
    "                child_i.append(B_j)\n",
    "        new_p_set = np.vstack([new_p_set, child_i])\n",
    "    return new_p_set\n",
    "\n",
    "def mutation(p_set, pm):\n",
    "    n = len(p_set)\n",
    "    d = len(p_set[0])\n",
    "    for i in range(n):\n",
    "        for j in range(d):\n",
    "            if rand.random() < pm:\n",
    "                p_set[i][j] = (rand.random()*2-1)*2\n",
    "    return p_set\n",
    "\n",
    "def survivor(p_set, n, fitness):\n",
    "    indexes = np.argsort(fitness)[:10]\n",
    "    fitness = np.sort(fitness)[:10]\n",
    "    return p_set[indexes]\n",
    "    \n",
    "def genetic_optimize(f, d, n, max_iter=1000, max_eval=1000000):\n",
    "    # genetic algorithm hyperparameters\n",
    "    # pc: probability of crossover, pm: probability of mutation\n",
    "    \n",
    "    pc = 0.4\n",
    "    pm = 0.6\n",
    "    \n",
    "    # initialize and evaluate n potential solutions P(t)\n",
    "    # limit the search space to +- 10 for each dimension\n",
    "    \n",
    "    p_set = (0.5-np.random.rand(1,d))*20\n",
    "    for i in range(n-1):\n",
    "        p = (0.5-np.random.rand(1,d))*20\n",
    "        p_set = np.vstack([p_set, p])\n",
    "        \n",
    "    terminate = False\n",
    "    i = 0\n",
    "    i_no_improvement = 0\n",
    "    cur_sol = []\n",
    "    evals = 0\n",
    "    \n",
    "    fitness = np.apply_along_axis(f, 1, p_set)\n",
    "    pop_fitness = fitness.mean()\n",
    "    evals += p_set.shape[0]\n",
    "    \n",
    "    while not terminate: \n",
    "        # Recombine P(t) to form C(t)\n",
    "        # parent selection\n",
    "        parents = selection(fitness, round(pc*n))\n",
    "        # crossover\n",
    "        p_set = crossover(p_set, parents)\n",
    "        \n",
    "        # mutation\n",
    "        p_set = np.vstack([p_set,mutation(p_set[:n,:],pm)])\n",
    "        \n",
    "        # survivor selection\n",
    "        fitness = np.apply_along_axis(f, 1, p_set)\n",
    "        p_set = survivor(p_set, n, fitness)\n",
    "        evals += p_set.shape[0]\n",
    "        \n",
    "        # check for termination criteria\n",
    "        if fitness.mean() >= pop_fitness:\n",
    "            i_no_improvement += 1\n",
    "        else:\n",
    "            i_no_improvement = 0\n",
    "            pop_fitness = fitness.mean()\n",
    "                          \n",
    "        if i > max_iter:\n",
    "            terminate = True\n",
    "        elif i_no_improvement > 10:\n",
    "            terminate = True\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        fitness = np.apply_along_axis(f, 1, p_set)\n",
    "        cur_sol.append(p_set[np.argsort(fitness)[0]])\n",
    "        \n",
    "        if evals > max_eval:\n",
    "            break\n",
    "        \n",
    "    #fitness = np.apply_along_axis(f, 1, p_set)\n",
    "    #indexes = np.argsort(fitness)\n",
    "    print('number of iterations: {}'.format(i))\n",
    "    return cur_sol #p_set[indexes[0]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of iterations: 57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.60549292,  1.25708193,  0.21237076, -0.9357967 , -0.20077471]),\n",
       " array([ 0.60549292,  0.19705181,  0.70557695,  1.17186409, -0.20077471]),\n",
       " array([ 0.60549292,  0.19705181,  0.08032394, -0.47901721,  0.0346049 ]),\n",
       " array([ 0.60549292,  0.19705181,  0.08032394, -0.47901721,  0.0346049 ]),\n",
       " array([ 0.60549292,  0.19705181,  0.08222317, -0.47901721,  0.0346049 ]),\n",
       " array([ 0.77625914,  0.19705181,  0.14603683,  0.0202602 , -0.1345386 ]),\n",
       " array([ 0.77625914,  0.35458983,  0.14603683,  0.0202602 , -0.1345386 ]),\n",
       " array([ 0.77625914,  0.35458983,  0.14603683,  0.0202602 , -0.19955534]),\n",
       " array([ 1.00022554,  0.88876749,  0.57700855, -0.19429997,  0.40769615]),\n",
       " array([-1.27534381,  0.88876749,  0.57700855,  0.66921407,  0.40769615]),\n",
       " array([-0.07480995,  0.94851779,  0.96719353,  0.10286632,  0.02682493]),\n",
       " array([-1.03198005,  1.32591427,  0.96719353,  0.33718828, -0.47178732]),\n",
       " array([-0.82507128,  1.32591427,  0.96719353,  0.95241192,  0.0445622 ]),\n",
       " array([-0.49514149, -0.04340495,  0.0397839 , -0.73787092,  1.43339223]),\n",
       " array([-0.82507128, -0.19563305, -0.91441426,  0.95241192,  1.57192735]),\n",
       " array([0.05629246, 0.94808445, 0.58131065, 0.47257653, 0.32697997]),\n",
       " array([-0.57682823,  0.27686065,  0.3148741 , -0.39525312,  1.03454176]),\n",
       " array([ 0.16815366,  0.27686065,  0.19056492, -0.39525312,  1.03454176]),\n",
       " array([ 0.16815366,  0.27686065, -0.10029307,  0.70578198,  1.03454176]),\n",
       " array([-0.83064159,  0.40567243, -0.10029307, -0.65693794,  1.02578592]),\n",
       " array([-0.62394326,  0.2026921 ,  0.58131065,  0.70578198,  1.03454176]),\n",
       " array([ 0.66223904,  0.39765484, -0.41899915, -0.41858455, -0.28969806]),\n",
       " array([ 0.24234007,  0.38508685, -0.41899915,  0.62065501,  1.03454176]),\n",
       " array([-0.62394326,  1.0216994 ,  0.23201008,  0.61438891,  1.10068809]),\n",
       " array([ 0.87060661,  0.67445486,  0.49641448, -0.03996832,  0.01059959]),\n",
       " array([-0.95105023,  0.67445486,  0.49641448, -0.03996832,  0.01059959]),\n",
       " array([-0.95105023,  0.67445486,  0.49641448, -0.59549252,  0.01059959]),\n",
       " array([ 0.10627853,  0.83138413,  0.22667296,  0.2003736 , -0.47280132]),\n",
       " array([1.11165768, 1.1833409 , 0.22667296, 0.21158829, 0.43160433]),\n",
       " array([ 0.02243746,  0.62323002, -0.67000344, -0.61399039,  0.52448826]),\n",
       " array([ 0.27429398, -0.11380621,  0.08125489,  0.15402386,  0.28186215]),\n",
       " array([ 0.27429398, -0.11380621,  0.08125489, -0.11710815,  0.28186215]),\n",
       " array([ 0.27429398, -0.11380621, -0.88902652,  1.08833918,  1.47586418]),\n",
       " array([-0.09500254,  0.99113171,  0.9298514 ,  0.75083829,  0.28186215]),\n",
       " array([-0.75638084,  0.99113171,  0.9298514 ,  1.1672358 ,  1.09776227]),\n",
       " array([0.27429398, 0.64052059, 0.25218065, 0.1278033 , 0.23753809]),\n",
       " array([0.64977728, 0.60524208, 0.51852992, 0.79195501, 1.09776227]),\n",
       " array([-1.08077584,  0.64052059,  0.25218065,  0.78172842,  0.90210249]),\n",
       " array([ 0.63825766,  0.62288134,  0.25218065, -0.34474227,  1.423016  ]),\n",
       " array([0.63825766, 0.62288134, 1.06455805, 0.54773733, 1.04518104]),\n",
       " array([ 0.63825766,  1.0736917 ,  1.06455805,  0.49720173, -0.30453509]),\n",
       " array([-0.00214276,  0.88234034,  1.06455805,  0.49720173,  1.1362021 ]),\n",
       " array([-0.78417699,  0.62288134,  0.49843835,  0.82301802, -0.00149645]),\n",
       " array([ 1.16022529,  0.62288134,  0.49843835,  0.44795097, -0.00149645]),\n",
       " array([-0.00042735,  0.62288134,  0.49843835,  0.44795097, -0.00149645]),\n",
       " array([ 0.99481251,  0.97994877,  0.49843835, -0.17732437,  0.13691537]),\n",
       " array([-0.00042735,  0.65522507,  0.49843835,  0.44357891, -0.5218608 ]),\n",
       " array([ 0.4300482 ,  0.3654984 ,  0.4065156 ,  0.44357891, -0.01379264]),\n",
       " array([-0.08293768,  0.3654984 , -0.60982464,  0.44467193, -0.00764454]),\n",
       " array([-0.08293768,  0.3654984 ,  0.92314826,  0.43395277, -0.73970124]),\n",
       " array([1.36722806, 1.02098756, 1.40575772, 1.39692884, 1.4269273 ]),\n",
       " array([ 0.67424709, -0.98445917,  1.40575772,  1.39692884,  0.77262863]),\n",
       " array([ 0.73728816,  0.32991769, -0.07748548, -0.0195279 ,  0.27129463]),\n",
       " array([ 0.73728816,  0.32991769, -0.07748548, -0.0195279 ,  0.27129463]),\n",
       " array([ 0.73728816,  0.32991769, -0.04940152, -0.27266266,  0.27129463]),\n",
       " array([ 0.73728816,  0.47012504, -0.04940152, -0.23489492,  1.05649736]),\n",
       " array([ 0.64411238,  0.32991769, -0.04940152, -0.27266266, -0.29827658])]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genetic_optimize(rosen, 5, 20, 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import gammaln\n",
    "\n",
    "def get_neighbor_normal(current_state, bounds_range, max_temp, current_temp):\n",
    "    sd_max = bounds_range/np.sqrt(12)\n",
    "    sd = sd_max/(0.95 * max_temp) * current_temp + 0.05 * sd_max\n",
    "    return np.random.normal(current_state, sd)\n",
    "\n",
    "def get_neighbor_cauchy(current_state, bounds_range, min_bounds, max_bounds, \n",
    "                  current_temp, qv):\n",
    "    factor2 = np.exp((4.0 - qv) * np.log(qv - 1.0))\n",
    "    factor3 = np.exp((2.0 - qv) * np.log(2.0)/(qv - 1.0))\n",
    "    factor4_p = np.sqrt(np.pi) * factor2 / factor3 * (3.0 - qv)\n",
    "    factor5 = 1.0 / (qv - 1.0) - 0.5\n",
    "    d1 = 2.0 - factor5\n",
    "    factor6 = np.pi * (1.0 - factor5) / np.sin(np.pi * (1.0 - factor5))/ \\\n",
    "    np.exp(gammaln(d1))\n",
    "    dim = len(current_state)\n",
    "    \n",
    "    x, y = np.random.normal(size=(dim, 2)).T\n",
    "    factor1 = np.exp(np.log(current_temp) / (qv - 1.0))\n",
    "    factor4 = factor4_p * factor1\n",
    "    \n",
    "    x *= np.exp(-(qv - 1.0) * np.log(factor6 / factor4) / (3.0 - qv))\n",
    "    den = np.exp((qv - 1.0) * np.log(np.fabs(y)) / (3.0 - qv))\n",
    "\n",
    "    visits = x / den\n",
    "    \n",
    "    TAIL_LIMIT = 1.e8\n",
    "    MIN_VISIT_BOUND = 1.e-10\n",
    "\n",
    "    upper_sample, lower_sample = np.random.uniform(size=2)\n",
    "    visits[visits > TAIL_LIMIT] = TAIL_LIMIT * upper_sample\n",
    "    visits[visits < TAIL_LIMIT] = TAIL_LIMIT * lower_sample\n",
    "    x_visit = visits + x\n",
    "    a = x_visit - min_bounds\n",
    "    b = np.fmod(a, bounds_range) + bounds_range\n",
    "    x_visit = np.fmod(b, bounds_range) + min_bounds\n",
    "    x_visit[np.fabs(x_visit - min_bounds) < MIN_VISIT_BOUND] += 1.e-10\n",
    "    \n",
    "    return x_visit\n",
    "    \n",
    "def simulated_annealing(f, bounds, initial_temp=5230, temp_func='', \n",
    "                        qv=2.62, get_neighbor='cauchy', maxiter=1000, \n",
    "                        max_eval=1000000):\n",
    "    # provide an initial state and temperature\n",
    "    time = 0\n",
    "    current_temp = initial_temp\n",
    "    min_temp = 0.1\n",
    "    \n",
    "    current_state = np.random.rand(len(bounds))\n",
    "    min_b, max_b = np.asarray(bounds).T\n",
    "    diff = max_b - min_b\n",
    "    current_state = min_b + current_state * diff\n",
    "\n",
    "    # evaluate current state\n",
    "    energy = f(current_state)\n",
    "    best_energy = energy\n",
    "    best_state = current_state\n",
    "    evals = 1\n",
    "    \n",
    "    for i in range(maxiter):\n",
    "        # generate a new state, randomly chosen neighbour of state\n",
    "        if get_neighbor == 'cauchy':\n",
    "            neighbor = get_neighbor_cauchy(current_state, diff, min_b, max_b, current_temp, qv)\n",
    "        else:\n",
    "            neighbor = get_neighbor_normal(current_state, diff, initial_temp, current_temp)\n",
    "        \n",
    "        # evaluate new neighbor\n",
    "        energy_neighbor = f(neighbor)\n",
    "        delta = energy_neighbor - energy\n",
    "        evals += 1\n",
    "   \n",
    "        if delta < 0:\n",
    "            current_state = neighbor\n",
    "            energy = energy_neighbor\n",
    "            best_energy = energy\n",
    "            best_state = current_state\n",
    "        else:\n",
    "            if np.random.rand() < np.exp(-delta/current_temp):\n",
    "                current_state = neighbor\n",
    "                energy = energy_neighbor\n",
    "        \n",
    "        time += 1\n",
    "        \n",
    "        alpha = (min_temp/initial_temp)**(1/maxiter)\n",
    "        \n",
    "        if temp_func == 'exponential':\n",
    "            current_temp = initial_temp*np.exp(-time) + 0.000001\n",
    "        elif temp_func == 'linear':\n",
    "            current_temp -= (initial_temp-min_temp)/maxiter\n",
    "        elif temp_func == 'ratio': \n",
    "            current_temp = alpha*current_temp\n",
    "        else:\n",
    "            current_temp = initial_temp*(2**(qv-1)-1)/((1+time)**(qv-1)-1)\n",
    " \n",
    "    return best_state, best_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(-10,10)]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.99062563, 0.9906154 , 0.99062586, 0.99061745, 0.99061709]),\n",
       " 0.03486474600121234)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulated_annealing(rosen, bounds, max_eval = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
