{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark function, Rosenbrock, global minima at x = 1\n",
    "def rosen(x):\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosen_with_noise(x, mu, sigma):\n",
    "    # assume normal distributed noise\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0) + np.random.normal(mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sphere(x):\n",
    "    return sum(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rastrigin(x):\n",
    "    return sum(10+x**2-10*np.cos(2*np.pi*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(n, bounds):\n",
    "    # generates a np array of n rows of random values that lies within the range given by bounds array\n",
    "    # bounds array is a list of tuples, each tuple indicate the (min value, max_value) for given dimension\n",
    "    # length of bounds is assumed to define the number of dimensions required\n",
    "    bounds_range = np.apply_along_axis(lambda x:x[1]-x[0], 1, np.array(bounds))\n",
    "    bounds_min = np.apply_along_axis(lambda x:x[0], 1, np.array(bounds))\n",
    "    p_set_norm = np.random.rand(1, len(bounds))\n",
    "    \n",
    "    for i in range(n-1):\n",
    "        p = np.random.rand(1, len(bounds))*bounds_range+bounds_min\n",
    "        p_set_norm = np.vstack([p_set_norm, p])\n",
    "        \n",
    "    p_set = p_set_norm*bounds_range+bounds_min    \n",
    "    return p_set_norm, p_set\n",
    "\n",
    "def select_vectors(p_set, r, exclude_i):\n",
    "    # chooses r vectors from the p_set, excluding the one at index: exclude_i \n",
    "    n = len(p_set)    \n",
    "    idexes = [idx for idx in range(n) if idx != exclude_i]\n",
    "    return p_set[np.random.choice(idexes, 3, replace=False)]\n",
    "\n",
    "def get_trial_vector(vectors, c):\n",
    "    # calculate trial vector using the 3 vector provided\n",
    "    if len(vectors) != 3:\n",
    "        return\n",
    "    return vectors[0] + c*(vectors[1] - vectors[2])\n",
    "\n",
    "def crossover(parent, trial_vector, pcr):\n",
    "    # if pcr = 1, means all choose from trial vector, if 0, means all choose from parent vector\n",
    "    choose_trial = np.random.rand(1,len(trial_vector)) <= pcr\n",
    "    return (choose_trial*trial_vector + (1-choose_trial)*parent)[0]\n",
    "    \n",
    "def differential_evolution(f, bounds, c=0.8, pcr=0.7, n=15, max_iter=1000, \n",
    "                           max_eval=1000000, init='latin'):\n",
    "    # finds minimal for function f subject to boundary given by bounds.    \n",
    "    # hyperparamters:\n",
    "    # n random starting positions\n",
    "    # c is the weight to multiply for the vector differential\n",
    "    # pcr is the rate of crossover\n",
    "    \n",
    "    # initialize n random starting positions\n",
    "    d = len(bounds) # dimension of inputs\n",
    "    p_set_norm, p_set = initialize(n, bounds)\n",
    "    bounds_range = np.apply_along_axis(lambda x:x[1]-x[0], 1, np.array(bounds))\n",
    "    bounds_min = np.apply_along_axis(lambda x:x[0], 1, np.array(bounds))\n",
    "    \n",
    "    # positions variables\n",
    "    fitness = np.apply_along_axis(f, 1, p_set)\n",
    "    mean_fitness = np.mean(fitness)\n",
    "    best_fitness = np.min(fitness)\n",
    "    best_position = p_set[np.argmin(fitness)]\n",
    "    best_position_list = []\n",
    "    \n",
    "    # loop variables\n",
    "    terminate = False\n",
    "    itr = 0\n",
    "    i_no_improvement = 0\n",
    "    evals = n\n",
    "    \n",
    "    while not terminate:\n",
    "        for i in range(n):\n",
    "            # select 3 other vectors from the positions and compute trial vector\n",
    "            trial_vector = get_trial_vector(select_vectors(p_set_norm, 3, i), c)\n",
    "            \n",
    "            # crossover\n",
    "            offspring_norm = crossover(p_set_norm[i], trial_vector, pcr)\n",
    "            offspring_norm = np.clip(offspring_norm, 0, 1)\n",
    "            offspring = offspring_norm*bounds_range+bounds_min \n",
    "            \n",
    "            # select fitter between offspring and parent\n",
    "            # minimization problem\n",
    "            offspring_fitness = f(offspring)\n",
    "            evals += 1\n",
    "            if offspring_fitness < f(p_set[i]):\n",
    "                p_set[i] = offspring\n",
    "                p_set_norm[i] = offspring_norm\n",
    "                \n",
    "                if offspring_fitness < best_fitness:\n",
    "                    best_fitness = offspring_fitness\n",
    "                    p_set[np.argmin(fitness)] = offspring\n",
    "                    p_set_norm[np.argmin(fitness)] = offspring_norm\n",
    "                    fitness[np.argmin(fitness)] = offspring_fitness\n",
    "                    best_position = offspring\n",
    "    \n",
    "        best_position_list.append(best_position)\n",
    "        \n",
    "        # check for termination criteria\n",
    "        if np.mean(fitness) >= mean_fitness:\n",
    "            i_no_improvement += 1\n",
    "        else:\n",
    "            mean_fitness = np.mean(fitness)\n",
    "            i_no_improvement = 0\n",
    "        \n",
    "        if itr > max_iter:\n",
    "            terminate = True\n",
    "        elif i_no_improvement > 100:\n",
    "            terminate = True\n",
    "        \n",
    "        if evals > max_eval:\n",
    "            terminate = True\n",
    "            \n",
    "        itr +=1\n",
    "    \n",
    "    print('the best solution is {} and function value is {}'.format(best_position, best_fitness))\n",
    "    print('number of iterations: {}'.format(itr))\n",
    "    return best_position_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best solution is [0.46891149 0.16576885 0.08459265 0.01804618] and function value is 2.446800327093799\n",
      "number of iterations: 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.46891149, 0.16576885, 0.08459265, 0.01804618]),\n",
       " array([-6.        , -4.66035447, -6.        , 10.        ]),\n",
       " array([-3.52196443, -5.72828358, -2.8       ,  2.8       ]),\n",
       " array([-3.52196443, -5.72828358, -2.8       ,  2.8       ]),\n",
       " array([-4.28605723,  5.43586926,  6.3136    , 10.        ]),\n",
       " array([1.34594277, 3.81349344, 2.04736   , 2.8       ]),\n",
       " array([ 1.34594277, -0.17894249,  1.6686848 ,  2.8       ]),\n",
       " array([ 1.34594277, -0.17894249,  1.6686848 ,  2.8       ]),\n",
       " array([ 1.34594277, -0.17894249,  1.6686848 ,  2.8       ]),\n",
       " array([ 1.34594277, -0.17894249,  1.6686848 ,  2.8       ]),\n",
       " array([ 1.34594277, -0.17894249,  1.6686848 ,  2.8       ]),\n",
       " array([ 1.34594277, -0.17894249,  1.6686848 ,  2.8       ]),\n",
       " array([ 1.34594277, -0.17894249,  1.6686848 ,  2.8       ]),\n",
       " array([ 1.34594277, -0.17894249,  1.6686848 ,  2.8       ]),\n",
       " array([ 0.63523715,  1.00566033, -0.45066765,  2.192     ]),\n",
       " array([ 0.63523715,  1.00566033, -0.45066765,  2.192     ]),\n",
       " array([ 0.63523715,  1.00566033, -0.45066765,  2.192     ]),\n",
       " array([0.41117967, 0.87854877, 0.79871154, 2.2432    ]),\n",
       " array([0.41117967, 0.87854877, 0.79871154, 2.2432    ]),\n",
       " array([0.41117967, 0.87854877, 0.79871154, 2.2432    ]),\n",
       " array([0.080545  , 0.70103731, 1.47666779, 2.8       ]),\n",
       " array([0.080545  , 0.70103731, 1.47666779, 2.8       ]),\n",
       " array([0.080545  , 0.70103731, 1.47666779, 2.8       ]),\n",
       " array([-0.70328065,  0.49886625,  1.09358859,  0.3168    ]),\n",
       " array([-0.70328065,  0.49886625,  1.09358859,  0.3168    ]),\n",
       " array([-1.07410643,  0.08330019, -0.11580302, -0.330112  ]),\n",
       " array([0.92839145, 1.25490886, 0.63313281, 0.87616   ]),\n",
       " array([0.92839145, 1.25490886, 0.63313281, 0.87616   ]),\n",
       " array([0.92839145, 1.25490886, 0.63313281, 0.87616   ]),\n",
       " array([0.92839145, 1.25490886, 0.63313281, 0.87616   ]),\n",
       " array([0.92839145, 0.48422294, 0.63313281, 0.228992  ]),\n",
       " array([0.92839145, 0.48422294, 0.63313281, 0.228992  ]),\n",
       " array([0.92839145, 0.48422294, 0.63313281, 0.228992  ]),\n",
       " array([0.92839145, 0.48422294, 0.63313281, 0.228992  ]),\n",
       " array([ 0.4849127 ,  0.26290413, -0.33578949,  0.38984684]),\n",
       " array([ 0.4849127 ,  0.26290413, -0.33578949,  0.38984684]),\n",
       " array([ 0.4849127 ,  0.26290413, -0.33578949,  0.38984684]),\n",
       " array([-0.06069462,  0.09535264, -0.14489687,  0.33140937]),\n",
       " array([-0.06069462,  0.09535264, -0.14489687,  0.33140937]),\n",
       " array([-0.06069462,  0.09535264, -0.14489687,  0.33140937]),\n",
       " array([-0.06069462,  0.09535264, -0.14489687,  0.33140937]),\n",
       " array([-0.06069462,  0.09535264, -0.14489687,  0.33140937]),\n",
       " array([-0.06069462,  0.09535264, -0.14489687,  0.33140937]),\n",
       " array([0.46891149, 0.16576885, 0.08459265, 0.01804618]),\n",
       " array([0.46891149, 0.16576885, 0.08459265, 0.01804618]),\n",
       " array([0.46891149, 0.16576885, 0.08459265, 0.01804618]),\n",
       " array([0.46891149, 0.16576885, 0.08459265, 0.01804618]),\n",
       " array([0.46891149, 0.16576885, 0.08459265, 0.01804618]),\n",
       " array([0.46891149, 0.16576885, 0.08459265, 0.01804618]),\n",
       " array([0.46891149, 0.16576885, 0.08459265, 0.01804618])]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = [(-10,10)]*4\n",
    "differential_evolution(rosen, bounds, n=20, max_eval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Space\n",
    "from skopt.sampler import Lhs\n",
    "\n",
    "def differential_evolution(f, bounds, mut=0.8, crossp=0.7, popsize=20, \n",
    "                           its=1000, init='latin', max_eval=1000000, display=False):\n",
    "    dimensions = len(bounds)\n",
    "    \n",
    "    # initialize positions\n",
    "    if init == 'random':\n",
    "        pop = np.random.rand(popsize, dimensions)\n",
    "    else:\n",
    "        space = Space([(0.,1.)]*dimensions)\n",
    "        lhs = Lhs()\n",
    "        pop = np.asarray(lhs.generate(space.dimensions, popsize))\n",
    "    \n",
    "    min_b, max_b = np.asarray(bounds).T\n",
    "    diff = max_b - min_b\n",
    "    pop_denorm = min_b + pop * diff\n",
    "    \n",
    "    # compute fitness\n",
    "    fitness = np.apply_along_axis(f, 1, pop_denorm)\n",
    "    best_idx = np.argmin(fitness)\n",
    "    best = pop_denorm[best_idx]\n",
    "    evals = popsize\n",
    "    \n",
    "    # main iteration\n",
    "    for i in range(its):\n",
    "        for j in range(popsize):\n",
    "            # generate 3 other random vectors \n",
    "            idxs = [idx for idx in range(popsize) if idx != j]\n",
    "            a, b, c = pop[np.random.choice(idxs, 3, replace = False)]\n",
    "            \n",
    "            # compute trial vector and perform boundary check\n",
    "            # perform cross over\n",
    "            mutant = np.clip(a + mut * (b - c), 0, 1)\n",
    "            cross_points = np.random.rand(dimensions) < crossp\n",
    "            trial = cross_points*mutant + (1-cross_points)*pop[j]\n",
    "            trial_denorm = min_b + trial * diff\n",
    "            \n",
    "            # compute fitness of trial vector\n",
    "            trial_fitness = f(trial_denorm)\n",
    "            evals += 1\n",
    "            \n",
    "            if trial_fitness < fitness[j]:\n",
    "                fitness[j] = trial_fitness\n",
    "                pop[j] = trial\n",
    "                if trial_fitness < fitness[best_idx]:\n",
    "                    best_idx = j\n",
    "                    best = trial_denorm\n",
    "        if display:\n",
    "            print('differential evolution step {}: f(x)= {}'.format(i, fitness[best_idx]))\n",
    "        \n",
    "        if evals > max_eval:\n",
    "            break\n",
    "    print('number of iterations: {}'.format(i))\n",
    "    return best, fitness[best_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on bechmark function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of iterations: 49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.75935754, 0.70920394, 0.75827669, 0.53232555]), 8.65875806308)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = [(-10,10)]*4\n",
    "differential_evolution(rosen, bounds, popsize=20, max_eval=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison to Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_DE(xk, convergence):\n",
    "    if convergence > 1:\n",
    "        print(xk)\n",
    "        return True\n",
    "    else:\n",
    "        print(xk)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= 752.698\n",
      "[ 0.52634998 -1.07038683  3.18561172  8.9408933 ]\n",
      "differential_evolution step 2: f(x)= 349.571\n",
      "[-0.10312849  0.10857833  0.59905104  2.12507868]\n",
      "differential_evolution step 3: f(x)= 349.571\n",
      "[-0.10312849  0.10857833  0.59905104  2.12507868]\n",
      "differential_evolution step 4: f(x)= 209.392\n",
      "[-0.92713544  1.66240494  1.84205818  2.65051208]\n",
      "differential_evolution step 5: f(x)= 90.2939\n",
      "[1.1213635  1.47901768 1.26833128 1.53231854]\n",
      "differential_evolution step 6: f(x)= 42.3204\n",
      "[ 0.72442501  0.42328948 -0.40204975  0.38822157]\n",
      "differential_evolution step 7: f(x)= 42.3204\n",
      "[ 0.72442501  0.42328948 -0.40204975  0.38822157]\n",
      "differential_evolution step 8: f(x)= 42.3204\n",
      "[ 0.72442501  0.42328948 -0.40204975  0.38822157]\n",
      "differential_evolution step 9: f(x)= 42.3204\n",
      "[ 0.72442501  0.42328948 -0.40204975  0.38822157]\n",
      "differential_evolution step 10: f(x)= 25.7397\n",
      "[0.7478027  0.22045544 0.12780284 0.36569043]\n",
      "differential_evolution step 11: f(x)= 8.04114\n",
      "[0.569656   0.1975894  0.1901908  0.19929378]\n",
      "differential_evolution step 12: f(x)= 8.04114\n",
      "[0.569656   0.1975894  0.1901908  0.19929378]\n",
      "differential_evolution step 13: f(x)= 8.04114\n",
      "[0.569656   0.1975894  0.1901908  0.19929378]\n",
      "differential_evolution step 14: f(x)= 8.04114\n",
      "[0.569656   0.1975894  0.1901908  0.19929378]\n",
      "differential_evolution step 15: f(x)= 8.04114\n",
      "[0.569656   0.1975894  0.1901908  0.19929378]\n",
      "differential_evolution step 16: f(x)= 5.28699\n",
      "[0.73672089 0.37518026 0.09606941 0.1093411 ]\n",
      "differential_evolution step 17: f(x)= 5.28699\n",
      "[0.73672089 0.37518026 0.09606941 0.1093411 ]\n",
      "differential_evolution step 18: f(x)= 1.27378\n",
      "[0.75413789 0.52605513 0.27587689 0.02298399]\n",
      "differential_evolution step 19: f(x)= 1.27378\n",
      "[0.75413789 0.52605513 0.27587689 0.02298399]\n",
      "differential_evolution step 20: f(x)= 1.27378\n",
      "[0.75413789 0.52605513 0.27587689 0.02298399]\n",
      "differential_evolution step 21: f(x)= 1.17217\n",
      "[0.84061537 0.65131618 0.42853495 0.12113338]\n",
      "differential_evolution step 22: f(x)= 1.13011\n",
      "[0.84061537 0.65131618 0.37219845 0.12737879]\n",
      "differential_evolution step 23: f(x)= 1.13011\n",
      "[0.84061537 0.65131618 0.37219845 0.12737879]\n",
      "differential_evolution step 24: f(x)= 1.13011\n",
      "[0.84061537 0.65131618 0.37219845 0.12737879]\n",
      "differential_evolution step 25: f(x)= 1.13011\n",
      "[0.84061537 0.65131618 0.37219845 0.12737879]\n",
      "differential_evolution step 26: f(x)= 1.13011\n",
      "[0.84061537 0.65131618 0.37219845 0.12737879]\n",
      "differential_evolution step 27: f(x)= 0.716442\n",
      "[0.84971401 0.76760366 0.61995968 0.42828784]\n",
      "differential_evolution step 28: f(x)= 0.370568\n",
      "[0.89810344 0.8259339  0.65401862 0.39715736]\n",
      "differential_evolution step 29: f(x)= 0.370568\n",
      "[0.89810344 0.8259339  0.65401862 0.39715736]\n",
      "differential_evolution step 30: f(x)= 0.370568\n",
      "[0.89810344 0.8259339  0.65401862 0.39715736]\n",
      "differential_evolution step 31: f(x)= 0.370568\n",
      "[0.89810344 0.8259339  0.65401862 0.39715736]\n",
      "differential_evolution step 32: f(x)= 0.370568\n",
      "[0.89810344 0.8259339  0.65401862 0.39715736]\n",
      "differential_evolution step 33: f(x)= 0.335683\n",
      "[0.90924813 0.83481109 0.6980195  0.44225153]\n",
      "differential_evolution step 34: f(x)= 0.335683\n",
      "[0.90924813 0.83481109 0.6980195  0.44225153]\n",
      "differential_evolution step 35: f(x)= 0.335683\n",
      "[0.90924813 0.83481109 0.6980195  0.44225153]\n",
      "differential_evolution step 36: f(x)= 0.151916\n",
      "[0.95116575 0.89150516 0.78455483 0.64071197]\n",
      "differential_evolution step 37: f(x)= 0.0759297\n",
      "[0.96417424 0.92156768 0.83931356 0.68825335]\n",
      "differential_evolution step 38: f(x)= 0.0759297\n",
      "[0.96417424 0.92156768 0.83931356 0.68825335]\n",
      "differential_evolution step 39: f(x)= 0.0759297\n",
      "[0.96417424 0.92156768 0.83931356 0.68825335]\n",
      "differential_evolution step 40: f(x)= 0.0575681\n",
      "[0.97048094 0.95443245 0.92785082 0.8679411 ]\n",
      "differential_evolution step 41: f(x)= 0.0432542\n",
      "[0.95934633 0.92464688 0.86129403 0.73141743]\n",
      "differential_evolution step 42: f(x)= 0.0432542\n",
      "[0.95934633 0.92464688 0.86129403 0.73141743]\n",
      "differential_evolution step 43: f(x)= 0.016135\n",
      "[0.98462876 0.96333346 0.93229133 0.86257697]\n",
      "differential_evolution step 44: f(x)= 0.016135\n",
      "[0.98462876 0.96333346 0.93229133 0.86257697]\n",
      "differential_evolution step 45: f(x)= 0.0114142\n",
      "[0.9983331  1.00576562 1.01073801 1.02699471]\n",
      "differential_evolution step 46: f(x)= 0.0114142\n",
      "[0.9983331  1.00576562 1.01073801 1.02699471]\n",
      "differential_evolution step 47: f(x)= 0.00580548\n",
      "[0.99959715 1.00092858 0.99551539 0.98722893]\n",
      "differential_evolution step 48: f(x)= 0.00580548\n",
      "[0.99959715 1.00092858 0.99551539 0.98722893]\n",
      "differential_evolution step 49: f(x)= 0.00580548\n",
      "[0.99959715 1.00092858 0.99551539 0.98722893]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.99959715, 1.00092858, 0.99551539, 0.98722893]), 0.005805478575822538)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import rosen, differential_evolution\n",
    "result = differential_evolution(rosen, bounds, popsize=20, maxiter=49, disp=True, callback=callback_DE, polish=False)\n",
    "result.x, result.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(fitness, n):\n",
    "    # calculate probability of each p being selected as a parent\n",
    "    f_inv = 1/(fitness/fitness.sum())\n",
    "    prob = f_inv/f_inv.sum()\n",
    "    # selecting n set of parents\n",
    "    indexes = np.argsort(prob)[::-1]\n",
    "    prob = np.sort(prob)[::-1]\n",
    "    parents = []\n",
    "    position = len(fitness)\n",
    "    for i in range(n):\n",
    "        parent = []\n",
    "        for i in range(2):\n",
    "            r = rand.random()\n",
    "            for j in range(position):\n",
    "                if r < prob[j]:\n",
    "                    parent.append(indexes[j])\n",
    "                    break\n",
    "                else:\n",
    "                    r -= prob[j]\n",
    "        parents.append(parent)\n",
    "    return parents\n",
    "        \n",
    "def crossover(p_set, parents):\n",
    "    # keep bits that are similar and perform uniform crossover for the rest\n",
    "    n = len(parents)\n",
    "    d = len(p_set[0])\n",
    "    new_p_set = np.copy(p_set)\n",
    "    for i in range(n):\n",
    "        parent_A = p_set[parents[i][0]]\n",
    "        parent_B = p_set[parents[i][1]]\n",
    "        \n",
    "        # go over each dimension and crossover if neccessary\n",
    "        child_i = []\n",
    "        for j in range(d):\n",
    "            A_j = parent_A[j]\n",
    "            B_j = parent_B[j]\n",
    "            \n",
    "            if abs(A_j - B_j) < 0.05:\n",
    "                child_i.append((A_j + B_j)/2)\n",
    "            elif rand.random() < 0.5:\n",
    "                child_i.append(A_j)\n",
    "            else:\n",
    "                child_i.append(B_j)\n",
    "        new_p_set = np.vstack([new_p_set, child_i])\n",
    "    return new_p_set\n",
    "\n",
    "def mutation(p_set, pm):\n",
    "    n = len(p_set)\n",
    "    d = len(p_set[0])\n",
    "    for i in range(n):\n",
    "        for j in range(d):\n",
    "            if rand.random() < pm:\n",
    "                p_set[i][j] = (rand.random()*2-1)*2\n",
    "    return p_set\n",
    "\n",
    "def survivor(p_set, n, fitness):\n",
    "    indexes = np.argsort(fitness)[:10]\n",
    "    fitness = np.sort(fitness)[:10]\n",
    "    return p_set[indexes]\n",
    "    \n",
    "def genetic_optimize(f, d, n, max_iter=1000, max_eval=1000000):\n",
    "    # genetic algorithm hyperparameters\n",
    "    # pc: probability of crossover, pm: probability of mutation\n",
    "    \n",
    "    pc = 0.4\n",
    "    pm = 0.6\n",
    "    \n",
    "    # initialize and evaluate n potential solutions P(t)\n",
    "    # limit the search space to +- 10 for each dimension\n",
    "    \n",
    "    p_set = (0.5-np.random.rand(1,d))*20\n",
    "    for i in range(n-1):\n",
    "        p = (0.5-np.random.rand(1,d))*20\n",
    "        p_set = np.vstack([p_set, p])\n",
    "        \n",
    "    terminate = False\n",
    "    i = 0\n",
    "    i_no_improvement = 0\n",
    "    cur_sol = []\n",
    "    evals = 0\n",
    "    \n",
    "    fitness = np.apply_along_axis(f, 1, p_set)\n",
    "    pop_fitness = fitness.mean()\n",
    "    evals += p_set.shape[0]\n",
    "    \n",
    "    while not terminate: \n",
    "        # Recombine P(t) to form C(t)\n",
    "        # parent selection\n",
    "        parents = selection(fitness, round(pc*n))\n",
    "        # crossover\n",
    "        p_set = crossover(p_set, parents)\n",
    "        \n",
    "        # mutation\n",
    "        p_set = np.vstack([p_set,mutation(p_set[:n,:],pm)])\n",
    "        \n",
    "        # survivor selection\n",
    "        fitness = np.apply_along_axis(f, 1, p_set)\n",
    "        p_set = survivor(p_set, n, fitness)\n",
    "        evals += p_set.shape[0]\n",
    "        \n",
    "        # check for termination criteria\n",
    "        if fitness.mean() >= pop_fitness:\n",
    "            i_no_improvement += 1\n",
    "        else:\n",
    "            i_no_improvement = 0\n",
    "            pop_fitness = fitness.mean()\n",
    "                          \n",
    "        if i > max_iter:\n",
    "            terminate = True\n",
    "        elif i_no_improvement > 10:\n",
    "            terminate = True\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        fitness = np.apply_along_axis(f, 1, p_set)\n",
    "        cur_sol.append(p_set[np.argsort(fitness)[0]])\n",
    "        \n",
    "        if evals > max_eval:\n",
    "            break\n",
    "        \n",
    "    #fitness = np.apply_along_axis(f, 1, p_set)\n",
    "    #indexes = np.argsort(fitness)\n",
    "    print('number of iterations: {}'.format(i))\n",
    "    return cur_sol #p_set[indexes[0]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of iterations: 57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.60549292,  1.25708193,  0.21237076, -0.9357967 , -0.20077471]),\n",
       " array([ 0.60549292,  0.19705181,  0.70557695,  1.17186409, -0.20077471]),\n",
       " array([ 0.60549292,  0.19705181,  0.08032394, -0.47901721,  0.0346049 ]),\n",
       " array([ 0.60549292,  0.19705181,  0.08032394, -0.47901721,  0.0346049 ]),\n",
       " array([ 0.60549292,  0.19705181,  0.08222317, -0.47901721,  0.0346049 ]),\n",
       " array([ 0.77625914,  0.19705181,  0.14603683,  0.0202602 , -0.1345386 ]),\n",
       " array([ 0.77625914,  0.35458983,  0.14603683,  0.0202602 , -0.1345386 ]),\n",
       " array([ 0.77625914,  0.35458983,  0.14603683,  0.0202602 , -0.19955534]),\n",
       " array([ 1.00022554,  0.88876749,  0.57700855, -0.19429997,  0.40769615]),\n",
       " array([-1.27534381,  0.88876749,  0.57700855,  0.66921407,  0.40769615]),\n",
       " array([-0.07480995,  0.94851779,  0.96719353,  0.10286632,  0.02682493]),\n",
       " array([-1.03198005,  1.32591427,  0.96719353,  0.33718828, -0.47178732]),\n",
       " array([-0.82507128,  1.32591427,  0.96719353,  0.95241192,  0.0445622 ]),\n",
       " array([-0.49514149, -0.04340495,  0.0397839 , -0.73787092,  1.43339223]),\n",
       " array([-0.82507128, -0.19563305, -0.91441426,  0.95241192,  1.57192735]),\n",
       " array([0.05629246, 0.94808445, 0.58131065, 0.47257653, 0.32697997]),\n",
       " array([-0.57682823,  0.27686065,  0.3148741 , -0.39525312,  1.03454176]),\n",
       " array([ 0.16815366,  0.27686065,  0.19056492, -0.39525312,  1.03454176]),\n",
       " array([ 0.16815366,  0.27686065, -0.10029307,  0.70578198,  1.03454176]),\n",
       " array([-0.83064159,  0.40567243, -0.10029307, -0.65693794,  1.02578592]),\n",
       " array([-0.62394326,  0.2026921 ,  0.58131065,  0.70578198,  1.03454176]),\n",
       " array([ 0.66223904,  0.39765484, -0.41899915, -0.41858455, -0.28969806]),\n",
       " array([ 0.24234007,  0.38508685, -0.41899915,  0.62065501,  1.03454176]),\n",
       " array([-0.62394326,  1.0216994 ,  0.23201008,  0.61438891,  1.10068809]),\n",
       " array([ 0.87060661,  0.67445486,  0.49641448, -0.03996832,  0.01059959]),\n",
       " array([-0.95105023,  0.67445486,  0.49641448, -0.03996832,  0.01059959]),\n",
       " array([-0.95105023,  0.67445486,  0.49641448, -0.59549252,  0.01059959]),\n",
       " array([ 0.10627853,  0.83138413,  0.22667296,  0.2003736 , -0.47280132]),\n",
       " array([1.11165768, 1.1833409 , 0.22667296, 0.21158829, 0.43160433]),\n",
       " array([ 0.02243746,  0.62323002, -0.67000344, -0.61399039,  0.52448826]),\n",
       " array([ 0.27429398, -0.11380621,  0.08125489,  0.15402386,  0.28186215]),\n",
       " array([ 0.27429398, -0.11380621,  0.08125489, -0.11710815,  0.28186215]),\n",
       " array([ 0.27429398, -0.11380621, -0.88902652,  1.08833918,  1.47586418]),\n",
       " array([-0.09500254,  0.99113171,  0.9298514 ,  0.75083829,  0.28186215]),\n",
       " array([-0.75638084,  0.99113171,  0.9298514 ,  1.1672358 ,  1.09776227]),\n",
       " array([0.27429398, 0.64052059, 0.25218065, 0.1278033 , 0.23753809]),\n",
       " array([0.64977728, 0.60524208, 0.51852992, 0.79195501, 1.09776227]),\n",
       " array([-1.08077584,  0.64052059,  0.25218065,  0.78172842,  0.90210249]),\n",
       " array([ 0.63825766,  0.62288134,  0.25218065, -0.34474227,  1.423016  ]),\n",
       " array([0.63825766, 0.62288134, 1.06455805, 0.54773733, 1.04518104]),\n",
       " array([ 0.63825766,  1.0736917 ,  1.06455805,  0.49720173, -0.30453509]),\n",
       " array([-0.00214276,  0.88234034,  1.06455805,  0.49720173,  1.1362021 ]),\n",
       " array([-0.78417699,  0.62288134,  0.49843835,  0.82301802, -0.00149645]),\n",
       " array([ 1.16022529,  0.62288134,  0.49843835,  0.44795097, -0.00149645]),\n",
       " array([-0.00042735,  0.62288134,  0.49843835,  0.44795097, -0.00149645]),\n",
       " array([ 0.99481251,  0.97994877,  0.49843835, -0.17732437,  0.13691537]),\n",
       " array([-0.00042735,  0.65522507,  0.49843835,  0.44357891, -0.5218608 ]),\n",
       " array([ 0.4300482 ,  0.3654984 ,  0.4065156 ,  0.44357891, -0.01379264]),\n",
       " array([-0.08293768,  0.3654984 , -0.60982464,  0.44467193, -0.00764454]),\n",
       " array([-0.08293768,  0.3654984 ,  0.92314826,  0.43395277, -0.73970124]),\n",
       " array([1.36722806, 1.02098756, 1.40575772, 1.39692884, 1.4269273 ]),\n",
       " array([ 0.67424709, -0.98445917,  1.40575772,  1.39692884,  0.77262863]),\n",
       " array([ 0.73728816,  0.32991769, -0.07748548, -0.0195279 ,  0.27129463]),\n",
       " array([ 0.73728816,  0.32991769, -0.07748548, -0.0195279 ,  0.27129463]),\n",
       " array([ 0.73728816,  0.32991769, -0.04940152, -0.27266266,  0.27129463]),\n",
       " array([ 0.73728816,  0.47012504, -0.04940152, -0.23489492,  1.05649736]),\n",
       " array([ 0.64411238,  0.32991769, -0.04940152, -0.27266266, -0.29827658])]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genetic_optimize(rosen, 5, 20, 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import gammaln\n",
    "\n",
    "def get_neighbor_normal(current_state, bounds_range, max_temp, current_temp):\n",
    "    sd_max = bounds_range/np.sqrt(12)\n",
    "    sd = sd_max/(0.95 * max_temp) * current_temp + 0.05 * sd_max\n",
    "    return np.random.normal(current_state, sd)\n",
    "\n",
    "def get_neighbor_cauchy(current_state, bounds_range, min_bounds, max_bounds, \n",
    "                  current_temp, qv):\n",
    "    factor2 = np.exp((4.0 - qv) * np.log(qv - 1.0))\n",
    "    factor3 = np.exp((2.0 - qv) * np.log(2.0)/(qv - 1.0))\n",
    "    factor4_p = np.sqrt(np.pi) * factor2 / factor3 * (3.0 - qv)\n",
    "    factor5 = 1.0 / (qv - 1.0) - 0.5\n",
    "    d1 = 2.0 - factor5\n",
    "    factor6 = np.pi * (1.0 - factor5) / np.sin(np.pi * (1.0 - factor5))/ \\\n",
    "    np.exp(gammaln(d1))\n",
    "    dim = len(current_state)\n",
    "    \n",
    "    x, y = np.random.normal(size=(dim, 2)).T\n",
    "    factor1 = np.exp(np.log(current_temp) / (qv - 1.0))\n",
    "    factor4 = factor4_p * factor1\n",
    "    \n",
    "    x *= np.exp(-(qv - 1.0) * np.log(factor6 / factor4) / (3.0 - qv))\n",
    "    den = np.exp((qv - 1.0) * np.log(np.fabs(y)) / (3.0 - qv))\n",
    "\n",
    "    visits = x / den\n",
    "    \n",
    "    TAIL_LIMIT = 1.e8\n",
    "    MIN_VISIT_BOUND = 1.e-10\n",
    "\n",
    "    upper_sample, lower_sample = np.random.uniform(size=2)\n",
    "    visits[visits > TAIL_LIMIT] = TAIL_LIMIT * upper_sample\n",
    "    visits[visits < TAIL_LIMIT] = TAIL_LIMIT * lower_sample\n",
    "    x_visit = visits + x\n",
    "    a = x_visit - min_bounds\n",
    "    b = np.fmod(a, bounds_range) + bounds_range\n",
    "    x_visit = np.fmod(b, bounds_range) + min_bounds\n",
    "    x_visit[np.fabs(x_visit - min_bounds) < MIN_VISIT_BOUND] += 1.e-10\n",
    "    \n",
    "    return x_visit\n",
    "    \n",
    "def simulated_annealing(f, bounds, initial_temp=5230, temp_func='', \n",
    "                        qv=2.62, get_neighbor='cauchy', maxiter=1000, \n",
    "                        max_eval=1000000):\n",
    "    # provide an initial state and temperature\n",
    "    time = 0\n",
    "    current_temp = initial_temp\n",
    "    min_temp = 0.1\n",
    "    \n",
    "    current_state = np.random.rand(len(bounds))\n",
    "    min_b, max_b = np.asarray(bounds).T\n",
    "    diff = max_b - min_b\n",
    "    current_state = min_b + current_state * diff\n",
    "\n",
    "    # evaluate current state\n",
    "    energy = f(current_state)\n",
    "    best_energy = energy\n",
    "    best_state = current_state\n",
    "    evals = 1\n",
    "    \n",
    "    for i in range(maxiter):\n",
    "        # generate a new state, randomly chosen neighbour of state\n",
    "        if get_neighbor == 'cauchy':\n",
    "            neighbor = get_neighbor_cauchy(current_state, diff, min_b, max_b, current_temp, qv)\n",
    "        else:\n",
    "            neighbor = get_neighbor_normal(current_state, diff, initial_temp, current_temp)\n",
    "        \n",
    "        # evaluate new neighbor\n",
    "        energy_neighbor = f(neighbor)\n",
    "        delta = energy_neighbor - energy\n",
    "        evals += 1\n",
    "   \n",
    "        if delta < 0:\n",
    "            current_state = neighbor\n",
    "            energy = energy_neighbor\n",
    "            best_energy = energy\n",
    "            best_state = current_state\n",
    "        else:\n",
    "            if np.random.rand() < np.exp(-delta/current_temp):\n",
    "                current_state = neighbor\n",
    "                energy = energy_neighbor\n",
    "        \n",
    "        time += 1\n",
    "        \n",
    "        alpha = (min_temp/initial_temp)**(1/maxiter)\n",
    "        \n",
    "        if temp_func == 'exponential':\n",
    "            current_temp = initial_temp*np.exp(-time) + 0.000001\n",
    "        elif temp_func == 'linear':\n",
    "            current_temp -= (initial_temp-min_temp)/maxiter\n",
    "        elif temp_func == 'ratio': \n",
    "            current_temp = alpha*current_temp\n",
    "        else:\n",
    "            current_temp = initial_temp*(2**(qv-1)-1)/((1+time)**(qv-1)-1)\n",
    " \n",
    "    return best_state, best_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on bechmark function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.02679571, 1.0262024 , 1.02566276, 1.02672742, 1.02612302,\n",
       "        1.02656624, 1.02639602, 1.02654015, 1.02685423, 1.02611376,\n",
       "        1.02680802, 1.02631129, 1.02696097, 1.02674777, 1.0268808 ,\n",
       "        1.02690537, 1.02653987, 1.02647278, 1.02664293, 1.02619786,\n",
       "        1.02633169, 1.02630398, 1.02638509, 1.02654859, 1.02673646,\n",
       "        1.02607189, 1.02683491, 1.02634176, 1.02618962, 1.02684825,\n",
       "        1.02608842, 1.02637982, 1.02641805, 1.0260934 , 1.02667631,\n",
       "        1.02682146, 1.02634162, 1.02601963, 1.02606674, 1.02631712,\n",
       "        1.02594888, 1.02675939, 1.02676613, 1.02704107, 1.02686178,\n",
       "        1.02661508, 1.02661775, 1.02665907, 1.02650972, 1.02679975]),\n",
       " 3.6599714813122883)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = [(-10,10)]*50\n",
    "simulated_annealing(rosen, bounds, max_eval = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Multi-starting point simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import gammaln\n",
    "\n",
    "def get_neighbor_normal(current_state, bounds_range, max_temp, current_temp):\n",
    "    sd_max = bounds_range/np.sqrt(12)\n",
    "    sd = sd_max/(0.95 * max_temp) * current_temp + 0.05 * sd_max\n",
    "    return np.random.normal(current_state, sd)\n",
    "\n",
    "def get_neighbor_cauchy(current_state, bounds_range, min_bounds, max_bounds, \n",
    "                  current_temp, qv):\n",
    "    factor2 = np.exp((4.0 - qv) * np.log(qv - 1.0))\n",
    "    factor3 = np.exp((2.0 - qv) * np.log(2.0)/(qv - 1.0))\n",
    "    factor4_p = np.sqrt(np.pi) * factor2 / factor3 * (3.0 - qv)\n",
    "    factor5 = 1.0 / (qv - 1.0) - 0.5\n",
    "    d1 = 2.0 - factor5\n",
    "    factor6 = np.pi * (1.0 - factor5) / np.sin(np.pi * (1.0 - factor5))/ \\\n",
    "    np.exp(gammaln(d1))\n",
    "    dim = len(current_state)\n",
    "    \n",
    "    x, y = np.random.normal(size=(dim, 2)).T\n",
    "    factor1 = np.exp(np.log(current_temp) / (qv - 1.0))\n",
    "    factor4 = factor4_p * factor1\n",
    "    \n",
    "    x *= np.exp(-(qv - 1.0) * np.log(factor6 / factor4) / (3.0 - qv))\n",
    "    den = np.exp((qv - 1.0) * np.log(np.fabs(y)) / (3.0 - qv))\n",
    "\n",
    "    visits = x / den\n",
    "    \n",
    "    TAIL_LIMIT = 1.e8\n",
    "    MIN_VISIT_BOUND = 1.e-10\n",
    "\n",
    "    upper_sample, lower_sample = np.random.uniform(size=2)\n",
    "    visits[visits > TAIL_LIMIT] = TAIL_LIMIT * upper_sample\n",
    "    visits[visits < TAIL_LIMIT] = TAIL_LIMIT * lower_sample\n",
    "    x_visit = visits + x\n",
    "    a = x_visit - min_bounds\n",
    "    b = np.fmod(a, bounds_range) + bounds_range\n",
    "    x_visit = np.fmod(b, bounds_range) + min_bounds\n",
    "    x_visit[np.fabs(x_visit - min_bounds) < MIN_VISIT_BOUND] += 1.e-10\n",
    "    \n",
    "    return x_visit\n",
    "    \n",
    "def simulated_annealing(f, bounds, initial_temp=5230, temp_func='', \n",
    "                        qv=2.62, get_neighbor='cauchy', maxiter=1000, \n",
    "                        max_eval=1000000):\n",
    "    # provide an initial state and temperature\n",
    "    time = 0\n",
    "    current_temp = initial_temp\n",
    "    min_temp = 0.1\n",
    "    \n",
    "    current_state = np.random.rand(len(bounds))\n",
    "    min_b, max_b = np.asarray(bounds).T\n",
    "    diff = max_b - min_b\n",
    "    current_state = min_b + current_state * diff\n",
    "\n",
    "    # evaluate current state\n",
    "    energy = f(current_state)\n",
    "    best_energy = energy\n",
    "    best_state = current_state\n",
    "    evals = 1\n",
    "    \n",
    "    for i in range(maxiter):\n",
    "        # generate a new state, randomly chosen neighbour of state\n",
    "        if get_neighbor == 'cauchy':\n",
    "            neighbor = get_neighbor_cauchy(current_state, diff, min_b, max_b, current_temp, qv)\n",
    "        else:\n",
    "            neighbor = get_neighbor_normal(current_state, diff, initial_temp, current_temp)\n",
    "        \n",
    "        # evaluate new neighbor\n",
    "        energy_neighbor = f(neighbor)\n",
    "        delta = energy_neighbor - energy\n",
    "        evals += 1\n",
    "   \n",
    "        if delta < 0:\n",
    "            current_state = neighbor\n",
    "            energy = energy_neighbor\n",
    "            best_energy = energy\n",
    "            best_state = current_state\n",
    "        else:\n",
    "            if np.random.rand() < np.exp(-delta/current_temp):\n",
    "                current_state = neighbor\n",
    "                energy = energy_neighbor\n",
    "        \n",
    "        time += 1\n",
    "        \n",
    "        alpha = (min_temp/initial_temp)**(1/maxiter)\n",
    "        \n",
    "        if temp_func == 'exponential':\n",
    "            current_temp = initial_temp*np.exp(-time) + 0.000001\n",
    "        elif temp_func == 'linear':\n",
    "            current_temp -= (initial_temp-min_temp)/maxiter\n",
    "        elif temp_func == 'ratio': \n",
    "            current_temp = alpha*current_temp\n",
    "        else:\n",
    "            current_temp = initial_temp*(2**(qv-1)-1)/((1+time)**(qv-1)-1)\n",
    " \n",
    "    return best_state, best_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Space\n",
    "from skopt.sampler import Lhs  \n",
    "\n",
    "class Particle:\n",
    "    def __init__(self, bounds, method='latin'):\n",
    "        self.dimensions = len(bounds)\n",
    "        self.position = np.empty(self.dimensions)\n",
    "        self.velocity = np.zeros(self.dimensions)\n",
    "        self.pbest_position = np.empty(self.dimensions)\n",
    "        self.pbest_value = None\n",
    "        self.lowerbounds, self.upperbounds = np.asarray(bounds).T\n",
    "        \n",
    "        # initialize positions\n",
    "        if method == 'random':\n",
    "            self.position = np.random.rand(self.dimensions)\n",
    "        elif method == 'latin':\n",
    "            space = Space([(0.,1.)]*self.dimensions)\n",
    "            lhs = Lhs()\n",
    "            self.position = np.asarray(lhs.generate(space.dimensions,1))[0]\n",
    "    \n",
    "    def evaluate(self, f):\n",
    "        cost = f(self.position)\n",
    "\n",
    "        if self.pbest_value == None:\n",
    "            self.pbest_value = cost\n",
    "        elif cost < self.pbest_value:\n",
    "\n",
    "            if sum(self.upperbounds < self.position)==0 and sum(self.lowerbounds > self.position)==0: \n",
    "                self.pbest_value = cost\n",
    "                self.pbest_position = self.position\n",
    "    \n",
    "    def update_velocity(self, gbest, inertia=0.5, c1=1, c2=2):\n",
    "        # c1: cognitive parameter, c2: social parameter\n",
    "        self.velocity = inertia*self.velocity + \\\n",
    "                        c1*np.random.rand()*(self.pbest_position-self.position) + \\\n",
    "                        c2*np.random.rand()*(gbest-self.position)\n",
    "    \n",
    "    def update_position(self):\n",
    "        self.position = self.position + self.velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Particle(bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-10, 10), (-10, 10)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur position [0.47630672 0.95290308]\n",
      "best position [1. 1.], value 1.1348923731875253\n",
      "velocity [-0.56414921 -1.48122477]\n",
      "after position [-0.08784249 -0.52832169]\n",
      "cur position [-0.08784249 -0.52832169]\n",
      "best position [-0.08784249 -0.52832169], value 0.2868401075926256\n",
      "velocity [-0.17430643 -0.09244922]\n",
      "after position [-0.26214892 -0.62077091]\n",
      "cur position [-0.26214892 -0.62077091]\n",
      "best position [-0.08784249 -0.52832169], value 0.2868401075926256\n",
      "velocity [0.35028005 0.91343418]\n",
      "after position [0.08813113 0.29266327]\n",
      "cur position [0.08813113 0.29266327]\n",
      "best position [0.08813113 0.29266327], value 0.09341888467046623\n",
      "velocity [0.16120857 0.41045391]\n",
      "after position [0.2493397  0.70311717]\n",
      "cur position [0.2493397  0.70311717]\n",
      "best position [0.08813113 0.29266327], value 0.09341888467046623\n",
      "velocity [-0.20920652 -0.57614906]\n",
      "after position [0.04013318 0.12696812]\n",
      "cur position [0.04013318 0.12696812]\n",
      "best position [0.04013318 0.12696812], value 0.01773157520922123\n",
      "velocity [-0.16473096 -0.47829871]\n",
      "after position [-0.12459778 -0.3513306 ]\n",
      "cur position [-0.12459778 -0.3513306 ]\n",
      "best position [0.04013318 0.12696812], value 0.01773157520922123\n",
      "velocity [-0.00445351 -0.01525919]\n",
      "after position [-0.12905129 -0.36658979]\n",
      "cur position [-0.12905129 -0.36658979]\n",
      "best position [0.04013318 0.12696812], value 0.01773157520922123\n",
      "velocity [0.16940761 0.48860204]\n",
      "after position [0.04035632 0.12201225]\n",
      "cur position [0.04035632 0.12201225]\n",
      "best position [0.04035632 0.12201225], value 0.016515622014139485\n",
      "velocity [0.0540186  0.15152818]\n",
      "after position [0.09437493 0.27354043]\n",
      "cur position [0.09437493 0.27354043]\n",
      "best position [0.04035632 0.12201225], value 0.016515622014139485\n",
      "velocity [-0.02698902 -0.0773022 ]\n",
      "after position [0.0673859  0.19623822]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"cur position {p.position}\")\n",
    "    p.evaluate(sphere)\n",
    "    print(f\"best position {p.pbest_position}, value {p.pbest_value}\")\n",
    "    p.update_velocity(np.array([0.,0.]))\n",
    "    print(f\"velocity {p.velocity}\")\n",
    "    p.update_position()\n",
    "    print(f\"after position {p.position}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def particle_swarm(f, bounds, popsize=20, max_iter=5000, max_eval=1000):\n",
    "    # initialize particles with random position and velocity\n",
    "    particles = []\n",
    "    for i in range(popsize):\n",
    "        particles.append(Particle(bounds))\n",
    "    \n",
    "    gbest_value = None\n",
    "    gbest_position = np.empty(len(bounds))\n",
    "    itr = 0\n",
    "    evals = 0\n",
    "    \n",
    "    while itr < max_iter:\n",
    "        # evaluate cost function and updates personal and global bests\n",
    "        for i in range(popsize):\n",
    "            particles[i].evaluate(f)\n",
    "            evals += 1\n",
    "            if gbest_value == None or particles[i].pbest_value < gbest_value:\n",
    "                gbest_value = particles[i].pbest_value\n",
    "                gbest_position = particles[i].pbest_position\n",
    "        \n",
    "        #print(f\"gbest value is {gbest_value}\")\n",
    "        # update particles velocity and new positions\n",
    "        for i in range(popsize):\n",
    "            particles[i].update_velocity(gbest_position)\n",
    "            particles[i].update_position()\n",
    "        \n",
    "        itr += 1\n",
    "        \n",
    "        if evals > max_eval:\n",
    "            break\n",
    "        \n",
    "    return gbest_position, gbest_value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(-10,10)]*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-cc7c2886dc2b>:3: RuntimeWarning: overflow encountered in square\n",
      "  return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.57476937, 0.54510486, 0.54179854, 0.5546148 , 0.46137056,\n",
       "        0.73300383, 0.65203154, 0.57497845, 0.57078461, 0.52137631,\n",
       "        0.51255382, 0.41079295, 0.5570628 , 0.3949505 , 0.38671514,\n",
       "        0.48135654, 0.45502753, 0.40505683, 0.41112971, 0.55655329,\n",
       "        0.39965213, 0.47343138, 0.49254045, 0.43356959, 0.40991641,\n",
       "        0.46155804, 0.48451361, 0.46342106, 0.55248351, 0.56168978,\n",
       "        0.38674346, 0.47726793, 0.58280906, 0.52636326, 0.58854702,\n",
       "        0.43614154, 0.42208777, 0.58078143, 0.4432474 , 0.50802685,\n",
       "        0.55306664, 0.46842265, 0.52269295, 0.63106955, 0.43844211,\n",
       "        0.38621419, 0.53036291, 0.48402731, 0.29401109, 0.42302058]),\n",
       " 346.3943744922239)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particle_swarm(rosen, bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
